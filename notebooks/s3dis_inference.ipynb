{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3DIS inference\n",
    "This notebook lets you run inference on the S3DIS Test Fold, from a pretrained model's checkpoint on your machine. The output will be a confusion matrix which you can save locally on your machine. For this, you must have done the following:\n",
    "- downloaded S3DIS dataset (if you haven't, instantiating the dataset will launch it for you though)\n",
    "- trained a model (which produced a checkpoint directory) or downloaded our pretrained weights\n",
    "\n",
    "Note this notebook should work for multimodal (2D+3D) and unimodal (3D only) experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select you GPU\n",
    "I_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use autoreload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from matplotlib.colors import ListedColormap\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_points3d.trainer import Trainer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "_ = torch.cuda.is_available()\n",
    "_ = torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(I_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "checkpoint_dir = '/directory/containing/your/checkpoint/file'\n",
    "result_dir = '/directory/where/to/save/inference/metrics'\n",
    "model_name = 'Res16UNet34-L4-early'                                   # adapt if you use another model in your checkpoint\n",
    "exp_name = None                                                       # you may give a name to the experiment\n",
    "exp_name = model_name if exp_name is None else exp_name\n",
    "n_votes = 1                                                           # number of inferences per spherical sample. For multi-inference voting with inference-time augmentation\n",
    "batch_size = 8                                                        # increase if your device allows it\n",
    "full_res = True                                                       # predictions will be made on the raw point cloud, at full resolution\n",
    "n_tries = 1                                                           # number of inferences \n",
    "num_workers = 4                                                       # increase if your machine allows it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Inference on S3DIS exp={exp_name}')\n",
    "\n",
    "# These are the arguments passed to Hydra. You could run the same thing \n",
    "# from CLI using `eval.py` with the command `python eval.py [...]`\n",
    "overrides = [\n",
    "    f'model_name={model_name}',\n",
    "    f\"checkpoint_dir={checkpoint_dir}\",\n",
    "    f'voting_runs={n_votes}',\n",
    "    f'tracker_options.full_res={full_res}',\n",
    "    'precompute_multi_scale=False',\n",
    "    f'num_workers={num_workers}',\n",
    "    f'batch_size={batch_size}',\n",
    "    f'cuda={I_GPU}',\n",
    "    'weight_name=last',\n",
    "]\n",
    "\n",
    "# Parse the arguments with Hydra and OmegaConf\n",
    "cfg = hydra_read(overrides, config_name='eval')\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "# Create the Trainer instance from your checkpoint\n",
    "trainer = Trainer(cfg)\n",
    "\n",
    "# Update the val and test transforms to match train transforms for \n",
    "# inference-time augmentation\n",
    "trainer._dataset.test_dataset[0].transform = trainer._dataset.train_dataset.transform\n",
    "if trainer._model.is_multimodal:\n",
    "    trainer._dataset.test_dataset[0].transform_image = trainer._dataset.train_dataset.transform_image\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[4].use_coverage = False\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[4].credit = int(2097152 * 2)\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[5].sigma = 0.02\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.saturation = [0.8, 1.2]\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.brightness = [0.8, 1.2]\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[6].transform.contrast = [0.8, 1.2]\n",
    "\n",
    "# Run inference\n",
    "for i_try in range(n_tries):\n",
    "    print(f'  run {i_try}/{n_tries}...')\n",
    "    trainer.eval(stage_name='test')\n",
    "    cm = trainer._tracker._full_confusion_matrix\n",
    "    torch.save(cm, f'{result_dir}/{exp_name}_votes-{trainer._cfg.voting_runs}_{i_try}.pt')\n",
    "    print(f'  mIoU={cm.get_average_intersection_union() * 100:0.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices will be saved in your `result_dir`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:depth_maps]",
   "language": "python",
   "name": "conda-env-depth_maps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
