{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITTI-360 inference\n",
    "This notebook lets you run inference on KITTI-360, from a pretrained model's checkpoint on your machine. The output will be a confusion matrix which you can save locally on your machine. For this, you must have done the following:\n",
    "- downloaded and preprocessed the KITTI-360 dataset (if you haven't, instantiating the dataset will launch it for you though)\n",
    "- trained a model (which produced a checkpoint directory) or downloaded our pretrained weights\n",
    "\n",
    "Note this notebook should work for multimodal (2D+3D) and unimodal (3D only) experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select you GPU\n",
    "I_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use autoreload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.cuda.set_device(I_GPU)\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_points3d.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "DATA_ROOT = '/path/to/your/dataset/root/directory'\n",
    "checkpoint_dir = '/directory/containing/your/checkpoint/file'\n",
    "result_dir = '/directory/where/to/save/inference/metrics'\n",
    "model_name = 'Res16UNet34-PointPyramid-early-cityscapes-interpolate'  # adapt if you use another model in your checkpoint\n",
    "split = 'val'                                                         # 'test' set will produce data for submission to the KITTI-360 3D semantic segmentation benchmark\n",
    "n_votes = 1                                                           # number of inferences per cylindrical sample. For multi-inference voting with inference-time augmentation\n",
    "sample_res = 1                                                        # saptial resolution of inference cylinder samples. Set to 3m for slower inference with +0.2 mIoU, roughly\n",
    "batch_size = 8                                                        # increase if your device allows it\n",
    "full_res = True                                                       # predictions will be made on the raw point cloud, at full resolution\n",
    "num_workers = 4                                                       # increase if your machine allows it\n",
    "exp_name = None                                                       # you may give a name to the experiment\n",
    "exp_name = f'{model_name}_{split}_votes-{n_votes}_sample_res-{sample_res}' if exp_name is None else exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Inference on KITTI360 exp={exp_name}')\n",
    "\n",
    "# These are the arguments passed to Hydra. You could run the same thing \n",
    "# from CLI using `eval.py` with the command `python eval.py [...]`\n",
    "overrides = [\n",
    "    f'model_name={model_name}',\n",
    "    f'checkpoint_dir={checkpoint_dir}',\n",
    "    f'voting_runs={n_votes}',\n",
    "    f'tracker_options.full_res={full_res}',\n",
    "    f'tracker_options.make_submission={split == \"test\"}',\n",
    "    'precompute_multi_scale=False',\n",
    "    f'num_workers={num_workers}',\n",
    "    f'batch_size={batch_size}',\n",
    "    f'cuda={I_GPU}',\n",
    "    'weight_name=latest',\n",
    "    f'+data.eval_sample_res={sample_res}',\n",
    "    f'+data.dataroot={DATA_ROOT}',\n",
    "]\n",
    "\n",
    "# Parse the arguments with Hydra and OmegaConf\n",
    "cfg = hydra_read(overrides, config_name='eval')\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "# Create the Trainer instance from your checkpoint\n",
    "trainer = Trainer(cfg)\n",
    "\n",
    "# Update the val and test transforms to match train transforms for \n",
    "# inference-time augmentation\n",
    "trainer._dataset.test_dataset[0].transform = trainer._dataset.train_dataset.transform\n",
    "if trainer._model.is_multimodal:\n",
    "    trainer._dataset.test_dataset[0].transform_image = trainer._dataset.train_dataset.transform_image\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[3].use_coverage = False\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[3].credit = int(1408 * 376 * 4 * 2)\n",
    "\n",
    "# Run inference\n",
    "trainer.eval(stage_name=split)\n",
    "cm = trainer._tracker._full_confusion_matrix\n",
    "torch.save(cm, f'{result_dir}/{exp_name}.pt')\n",
    "if split != 'test':\n",
    "    print(f'  mIoU={cm.get_average_intersection_union() * 100:0.2f}')\n",
    "    print(f'  OA={cm.get_overall_accuracy() * 100:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices will be saved in your `result_dir`. Please refer to `torch_points3d/metrics/confusion_matrix` if you need to compute more metrics from the confusion matrices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp3d",
   "language": "python",
   "name": "tp3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
