{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITTI-360 inference\n",
    "This notebook lets you run inference on KITTI-360, from a pretrained model's checkpoint on your machine. The output will be a confusion matrix which you can save locally on your machine. For this, you must have done the following:\n",
    "- downloaded KITTI-360 dataset (if you haven't, instantiating the dataset will launch it for you though)\n",
    "- trained a model (which produced a checkpoint directory) or downloaded our pretrained weights\n",
    "\n",
    "Note this notebook should work for multimodal (2D+3D) and unimodal (3D only) experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select you GPU\n",
    "I_GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use autoreload\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from matplotlib.colors import ListedColormap\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from torch_points3d.utils.config import hydra_read\n",
    "from torch_points3d.trainer import Trainer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DIR = os.path.dirname(os.getcwd())\n",
    "ROOT = os.path.join(DIR, \"..\")\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, DIR)\n",
    "\n",
    "_ = torch.cuda.is_available()\n",
    "_ = torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(I_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "checkpoint_dir = '/directory/containing/your/checkpoint/file'\n",
    "result_dir = '/directory/where/to/save/inference/metrics'\n",
    "model_name = 'Res16UNet34-PointPyramid-early-cityscapes-interpolate'  # adapt if you use another model in your checkpoint\n",
    "exp_name = None                                                       # you may give a name to the experiment\n",
    "exp_name = model_name if exp_name is None else exp_name\n",
    "split = 'val'                                                         # 'test' set will produce data for submission to the KITTI-360 3D semantic segmentation benchmark\n",
    "n_votes = 1                                                           # number of inferences per cylindrical sample. For multi-inference voting with inference-time augmentation\n",
    "sample_res = 6                                                        # saptial resolution of inference cylinder samples. Set to 3m for slower inference with +0.2 mIoU, roughly\n",
    "batch_size = 8                                                        # increase if your device allows it\n",
    "full_res = True                                                       # predictions will be made on the raw point cloud, at full resolution\n",
    "n_tries = 1                                                           # number of inferences \n",
    "num_workers = 4                                                       # increase if your machine allows it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Inference on KITTI360 exp={exp_name}')\n",
    "\n",
    "# These are the arguments passed to Hydra. You could run the same thing \n",
    "# from CLI using `eval.py` with the command `python eval.py [...]`\n",
    "overrides = [\n",
    "    f'model_name={model_name}',\n",
    "    f'checkpoint_dir={checkpoint_dir}',\n",
    "    f'voting_runs={n_votes}',\n",
    "    f'tracker_options.full_res={full_res}',\n",
    "    f'tracker_options.make_submission={split == \"test\"}',\n",
    "    'precompute_multi_scale=False',\n",
    "    f'num_workers={num_workers}',\n",
    "    f'batch_size={batch_size}',\n",
    "    f'cuda={I_GPU}',\n",
    "    'weight_name=last',\n",
    "    f'+data.eval_sample_res={sample_res}'\n",
    "]\n",
    "\n",
    "# Parse the arguments with Hydra and OmegaConf\n",
    "cfg = hydra_read(overrides, config_name='eval')\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "# Create the Trainer instance from your checkpoint\n",
    "trainer = Trainer(cfg)\n",
    "\n",
    "# Update the val and test transforms to match train transforms for \n",
    "# inference-time augmentation\n",
    "trainer._dataset.test_dataset[0].transform = trainer._dataset.train_dataset.transform\n",
    "if trainer._model.is_multimodal:\n",
    "    trainer._dataset.test_dataset[0].transform_image = trainer._dataset.train_dataset.transform_image\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[3].use_coverage = False\n",
    "    trainer._dataset.test_dataset[0].transform_image.transforms[3].credit = int(1408 * 376 * 4 * 2)\n",
    "\n",
    "# Run inference\n",
    "for i_try in range(n_tries):\n",
    "    print(f'  run {i_try}/{n_tries}...')\n",
    "    trainer.eval(stage_name=split)\n",
    "    cm = trainer._tracker._full_confusion_matrix\n",
    "    torch.save(cm, f'{result_dir}/{exp_name}_{split}_sample-res-{sample_res}_votes-{trainer._cfg.voting_runs}_{i_try}.pt')\n",
    "    if split != 'test':\n",
    "        print(f'  mIoU={cm.get_average_intersection_union() * 100:0.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices will be saved in your `result_dir`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tp3d_dev] *",
   "language": "python",
   "name": "conda-env-tp3d_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
